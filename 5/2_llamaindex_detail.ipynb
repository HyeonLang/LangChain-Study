{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOTadjFsf4AZfOYuG+kosi0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 라마인덱스 사전 준비\n","\n"],"metadata":{"id":"1JdDzC4uHPf5"}},{"cell_type":"code","source":["# 패키지 설치\n","!pip install llama-index\n","!pip install openai\n","!pip install langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KsW0wIw0HS6G","executionInfo":{"status":"ok","timestamp":1700006951448,"user_tz":-540,"elapsed":27840,"user":{"displayName":"김재우","userId":"05418694853631208143"}},"outputId":"7dd2371e-4f26-4127-8e5a-1e21cf6e42dd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index\n","  Downloading llama_index-0.8.69.post2-py3-none-any.whl (862 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.3/862.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n","Collecting aiostream<0.6.0,>=0.5.2 (from llama-index)\n","  Downloading aiostream-0.5.2-py3-none-any.whl (39 kB)\n","Collecting dataclasses-json<0.6.0,>=0.5.7 (from llama-index)\n","  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n","Collecting deprecated>=1.2.9.3 (from llama-index)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n","Collecting langchain>=0.0.303 (from llama-index)\n","  Downloading langchain-0.0.335-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n","Collecting openai>=1.1.0 (from llama-index)\n","  Downloading openai-1.2.4-py3-none-any.whl (220 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.2/220.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n","Collecting tiktoken>=0.3.3 (from llama-index)\n","  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n","Collecting typing-inspect>=0.8.0 (from llama-index)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting urllib3<2 (from llama-index)\n","  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->llama-index)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index) (1.14.1)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (6.0.1)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (3.8.6)\n","Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (3.7.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (4.0.3)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.0.303->llama-index)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langsmith<0.1.0,>=0.0.63 (from langchain>=0.0.303->llama-index)\n","  Downloading langsmith-0.0.64-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (1.10.13)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.303->llama-index) (2.31.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai>=1.1.0->llama-index)\n","  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (3.3.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.303->llama-index) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama-index) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama-index) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.303->llama-index) (1.1.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.1.0->llama-index) (2023.7.22)\n","Collecting httpcore (from httpx<1,>=0.23.0->openai>=1.1.0->llama-index)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.0.303->llama-index)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->llama-index) (23.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n","Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai>=1.1.0->llama-index)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: urllib3, mypy-extensions, marshmallow, jsonpointer, h11, deprecated, aiostream, typing-inspect, jsonpatch, httpcore, tiktoken, langsmith, httpx, dataclasses-json, openai, langchain, llama-index\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.7\n","    Uninstalling urllib3-2.0.7:\n","      Successfully uninstalled urllib3-2.0.7\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiostream-0.5.2 dataclasses-json-0.5.14 deprecated-1.2.14 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.335 langsmith-0.0.64 llama-index-0.8.69.post2 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.2.4 tiktoken-0.5.1 typing-inspect-0.9.0 urllib3-1.26.18\n","Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.2.4)\n","Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n","Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.335)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n","Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n","Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.64)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"]}]},{"cell_type":"code","source":["# 환경변수 준비\n","import openai\n","openai.api_key = \"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\""],"metadata":{"id":"g1kupVfeHbQ2","executionInfo":{"status":"ok","timestamp":1700006974460,"user_tz":-540,"elapsed":990,"user":{"displayName":"김재우","userId":"05418694853631208143"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[" import logging\n"," import sys\n","\n"," # 로그 레벨 설정\n"," logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)"],"metadata":{"id":"fVLHLRjvHgGU","executionInfo":{"status":"ok","timestamp":1700006977163,"user_tz":-540,"elapsed":3,"user":{"displayName":"김재우","userId":"05418694853631208143"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# 문서 로드"],"metadata":{"id":"smAXTLw0Hoj1"}},{"cell_type":"code","source":["from llama_index import SimpleDirectoryReader\n","\n","# 문서 로드\n","documents = SimpleDirectoryReader(\"data\").load_data()\n","print(\"documents :\", documents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1udyyW4HlUk","executionInfo":{"status":"ok","timestamp":1700006987956,"user_tz":-540,"elapsed":6790,"user":{"displayName":"김재우","userId":"05418694853631208143"}},"outputId":"2292c67c-e9ee-478b-f832-54360201640a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): openaipublic.blob.core.windows.net:443\n","DEBUG:urllib3.connectionpool:https://openaipublic.blob.core.windows.net:443 \"GET /gpt-2/encodings/main/vocab.bpe HTTP/1.1\" 200 456318\n","DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): openaipublic.blob.core.windows.net:443\n","DEBUG:urllib3.connectionpool:https://openaipublic.blob.core.windows.net:443 \"GET /gpt-2/encodings/main/encoder.json HTTP/1.1\" 200 1042301\n","INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","DEBUG:llama_index.readers.file.base:> [SimpleDirectoryReader] Total files added: 7\n","documents : [Document(id_='ccf9e8af-7ffb-4e00-aaaa-cb931b435eff', embedding=None, metadata={'file_path': 'data/akazukin1.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='245582517933e49af6dd0594d7f8f81f3546b1981bf292946289ddd85578b4ba', text=\"제1장: 데이터 프론트\\n\\n밤이 되면 반짝이는 네오 도쿄. 고층 빌딩이 늘어서고, 네온사인이 거리를 수놓는다. 그 거리에서 빨간 두건을 쓴 소녀 미코는 불법 데이터 카우리아를 운반하는 배달원으로 일하고 있었다. 그녀는 어머니가 병에 걸려 치료비를 벌기 위해 데이터카우리아에 몸을 던지고 있었다.\\n\\n그러던 어느 날, 미코는 중요한 데이터를 운반하는 임무를 맡게 된다. 그 데이터에는 거대 기업 '울프 코퍼레이션'의 시민에 대한 악랄한 지배를 폭로하는 정보가 담겨 있었다. 그녀는 데이터를 받아 목적지로 향한다.\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c71a3278-2f34-4d99-90e4-1357caba66c2', embedding=None, metadata={'file_path': 'data/akazukin2.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='0ddd94bab810992f00f6963e47acad3dfd91176fc1e68c028e3e0eb0880e1a9a', text=\"제2장: 울프 코퍼레이션의 함정\\n\\n미코는 목적지인 술집 '할머니의 집'으로 향하는 길에 울프 코퍼레이션의 요원들에게 쫓기게 된다. 그들은 '빨간 망토'라는 데이터 카우리아에 대한 소문을 듣고 데이터를 탈취하려 했다. 미코는 교묘하게 요원들을 흩뿌리고 술집에 도착한다.\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e8e205ea-b0c2-4dbb-8766-6fca40240bf1', embedding=None, metadata={'file_path': 'data/akazukin3.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='46ab05d7966d65d132d327118a460e5279798448f9b18456dc2c7a9573e528d3', text=\"제3장: 배신과 재회\\n\\n술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기다리고 있었다. 료는 그녀의 어릴 적 친구이자 그 역시 울프 코퍼레이션과 싸우는 해커 집단의 일원이었다. 하지만 료는 미코에게 배신감을 느꼈고, 그녀가 데이터 카우리아에 몸을 던진 것에 화가 났다.\\n\\n그럼에도 불구하고 미코는 료에게 데이터를 건네며 울프 코퍼레이션에 대한 반격을 믿기로 한다. 두 사람은 함께 울프 코퍼레이션의 음모를 밝혀내고 시민들을 구하기로 결심한다.\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='5bd695a3-d056-4200-95b5-bebb43bb6586', embedding=None, metadata={'file_path': 'data/akazukin4.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='e6aa8c11bfc10b0214ed71d3c550b94ad115932f3d7431e286b6f6e224d9440c', text='제4장: 울프 코퍼레이션의 붕괴\\n\\n미코와 료는 해커 집단과 함께 울프 코퍼레이션에 대한 최후의 결전을 벌인다. 능숙한 해킹 기술과 신체 능력으로 그들은 울프 코퍼레이션의 보안을 차례로 뚫어 나간다. 그 과정에서 미코는 울프 코퍼레이션이 어머니의 병에 관여하고 있다는 사실을 알게 된다. 그녀는 분노에 휩싸여 울프코퍼레이션에 대한 복수를 다짐한다.\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='ed7d46c6-003a-4ee0-80fa-a048399bbb30', embedding=None, metadata={'file_path': 'data/akazukin5.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='aaa833804c60686d89a7f25f5e4348481490c3542510cdf15e64392a8b89f734', text='제5장: 결전의 순간\\n\\n미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인 교활한 울프 박사와 대면한다. 울프 박사는 시민을 지배하려는 사악한 야망을 드러내며 자신의 압도적인 힘을 과시한다. 하지만 미코와 료는 서로를 도와가며 울프 박사와 싸우고 그의 약점을 찾아낸다.\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='87de9486-db9b-430c-8fda-2e1cbff49118', embedding=None, metadata={'file_path': 'data/akazukin6.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='86dbcf8e52affe0f54d8e94bc4ea8c5f59916cef28ab11f59f30ef32f7448e43', text='제6장: 진실의 해방\\n\\n미코는 울프 박사의 약점을 파고들어 그를 쓰러뜨리는데 성공한다. 그리고 해커 집단과 함께 울프 코퍼레이션의 악행을 세상에 공개하고 시민들을 해방시킨다. 이 승리로 미코의 어머니의 치료법도 찾아내고, 그녀의 병은 완치된다.\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e610b253-9127-4eb2-9fed-90ffbdafaad4', embedding=None, metadata={'file_path': 'data/akazukin7.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, hash='82734041f178c7caa85fc39a7ce4cc826aadbacfc66c1034765feb84305557d2', text='제7장: 새로운 시작\\n\\n울프 코퍼레이션이 무너진 후, 미코와 료는 서로의 과거를 용서하고 다시 우정을 회복한다. 미코는 데이터카우리아를 그만두고 료와 함께 새로운 길을 걷기 시작한다. 그들은 스스로의 힘으로 미래의 네오 도쿄를 더 나은 도시로 바꾸어 나갈 것을 다짐한다. 이것은 미코와 료, 그리고 전뇌 빨간 망토의 새로운 모험의 시작이었다.\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"]}]},{"cell_type":"code","source":["from llama_index import Document\n","\n","# 수동으로 문서 생성\n","texts = [\"text1\", \"text2\", \"text3\"]\n","documents = [Document(t) for t in texts]\n","print(\"documents :\", documents)\n"],"metadata":{"id":"1I4Olk-WHz7M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 인덱스 생성"],"metadata":{"id":"w8Le0F3TUNlp"}},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex\n","\n","# 인덱스 생성\n","index = GPTVectorStoreIndex.from_documents(documents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBz_AKMdULrq","executionInfo":{"status":"ok","timestamp":1700007139768,"user_tz":-540,"elapsed":4298,"user":{"displayName":"김재우","userId":"05418694853631208143"}},"outputId":"0e558fd0-5720-4142-e501-5d4cb1a599ac"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n","DEBUG:httpx:load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n","DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n","DEBUG:httpx:load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n","DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n","DEBUG:httpx:load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n","DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n","DEBUG:httpx:load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /tmp/llama_index...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제1장: 데이터 프론트\n","\n","밤이 되면 반짝이는 네오 도쿄. 고층 빌딩이 늘어서고, 네온...\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제2장: 울프 코퍼레이션의 함정\n","\n","미코는 목적지인 술집 '할머니의 집'으로 향하는 길...\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제3장: 배신과 재회\n","\n","술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기...\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제4장: 울프 코퍼레이션의 붕괴\n","\n","미코와 료는 해커 집단과 함께 울프 코퍼레이션에 대...\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제5장: 결전의 순간\n","\n","미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인...\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제6장: 진실의 해방\n","\n","미코는 울프 박사의 약점을 파고들어 그를 쓰러뜨리는데 성공한다...\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제7장: 새로운 시작\n","\n","울프 코퍼레이션이 무너진 후, 미코와 료는 서로의 과거를 용서...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb47a29b9a0>, 'json_data': {'input': [\"file_path: data/akazukin1.txt  제1장: 데이터 프론트  밤이 되면 반짝이는 네오 도쿄. 고층 빌딩이 늘어서고, 네온사인이 거리를 수놓는다. 그 거리에서 빨간 두건을 쓴 소녀 미코는 불법 데이터 카우리아를 운반하는 배달원으로 일하고 있었다. 그녀는 어머니가 병에 걸려 치료비를 벌기 위해 데이터카우리아에 몸을 던지고 있었다.  그러던 어느 날, 미코는 중요한 데이터를 운반하는 임무를 맡게 된다. 그 데이터에는 거대 기업 '울프 코퍼레이션'의 시민에 대한 악랄한 지배를 폭로하는 정보가 담겨 있었다. 그녀는 데이터를 받아 목적지로 향한다.\", \"file_path: data/akazukin2.txt  제2장: 울프 코퍼레이션의 함정  미코는 목적지인 술집 '할머니의 집'으로 향하는 길에 울프 코퍼레이션의 요원들에게 쫓기게 된다. 그들은 '빨간 망토'라는 데이터 카우리아에 대한 소문을 듣고 데이터를 탈취하려 했다. 미코는 교묘하게 요원들을 흩뿌리고 술집에 도착한다.\", \"file_path: data/akazukin3.txt  제3장: 배신과 재회  술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기다리고 있었다. 료는 그녀의 어릴 적 친구이자 그 역시 울프 코퍼레이션과 싸우는 해커 집단의 일원이었다. 하지만 료는 미코에게 배신감을 느꼈고, 그녀가 데이터 카우리아에 몸을 던진 것에 화가 났다.  그럼에도 불구하고 미코는 료에게 데이터를 건네며 울프 코퍼레이션에 대한 반격을 믿기로 한다. 두 사람은 함께 울프 코퍼레이션의 음모를 밝혀내고 시민들을 구하기로 결심한다.\", 'file_path: data/akazukin4.txt  제4장: 울프 코퍼레이션의 붕괴  미코와 료는 해커 집단과 함께 울프 코퍼레이션에 대한 최후의 결전을 벌인다. 능숙한 해킹 기술과 신체 능력으로 그들은 울프 코퍼레이션의 보안을 차례로 뚫어 나간다. 그 과정에서 미코는 울프 코퍼레이션이 어머니의 병에 관여하고 있다는 사실을 알게 된다. 그녀는 분노에 휩싸여 울프코퍼레이션에 대한 복수를 다짐한다.', 'file_path: data/akazukin5.txt  제5장: 결전의 순간  미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인 교활한 울프 박사와 대면한다. 울프 박사는 시민을 지배하려는 사악한 야망을 드러내며 자신의 압도적인 힘을 과시한다. 하지만 미코와 료는 서로를 도와가며 울프 박사와 싸우고 그의 약점을 찾아낸다.', 'file_path: data/akazukin6.txt  제6장: 진실의 해방  미코는 울프 박사의 약점을 파고들어 그를 쓰러뜨리는데 성공한다. 그리고 해커 집단과 함께 울프 코퍼레이션의 악행을 세상에 공개하고 시민들을 해방시킨다. 이 승리로 미코의 어머니의 치료법도 찾아내고, 그녀의 병은 완치된다.', 'file_path: data/akazukin7.txt  제7장: 새로운 시작  울프 코퍼레이션이 무너진 후, 미코와 료는 서로의 과거를 용서하고 다시 우정을 회복한다. 미코는 데이터카우리아를 그만두고 료와 함께 새로운 길을 걷기 시작한다. 그들은 스스로의 힘으로 미래의 네오 도쿄를 더 나은 도시로 바꾸어 나갈 것을 다짐한다. 이것은 미코와 료, 그리고 전뇌 빨간 망토의 새로운 모험의 시작이었다.'], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n","DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb47a2f04c0>\n","DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb4974a2ec0> server_hostname='api.openai.com' timeout=60.0\n","DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb47a2f0490>\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:12:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'47'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999117'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'52ms'), (b'x-request-id', b'8c10395c8ab607700992236dc0c88e4b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.6lZTMtlBdC3goIzJ82X1GhOxjJD6ncPq1Tww48l8MI-1700007137-0-AX7ML7/3b18pJdNKNQ9l/HhJEptQUetCMp/vbqQNJWyMyX2d4piWcddPG+9O/S5NzriSMZoeSyJXRCq2bCS+nHY=; path=/; expires=Wed, 15-Nov-23 00:42:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ixe.f7tOAEE8DC6usGD3W_HPJ5m_nxNrRRMJs7t08sw-1700007137632-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82634820eb08070f-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n"]}]},{"cell_type":"code","source":["from llama_index import GPTVectorStoreIndex\n","\n","# 빈 인덱스 생성\n","index = GPTVectorStoreIndex.from_documents([])\n","\n","# 문서를 인덱스에 삽입\n","for doc in documents:\n","  index.insert(doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XY0arh2Uj37","executionInfo":{"status":"ok","timestamp":1700007339199,"user_tz":-540,"elapsed":2267,"user":{"displayName":"김재우","userId":"05418694853631208143"}},"outputId":"36597ec2-1c06-49fb-be39-c70dcc2eb659"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n","DEBUG:httpx:load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n","DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n","DEBUG:httpx:load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n","DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n","DEBUG:httpx:load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n","DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n","DEBUG:httpx:load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제1장: 데이터 프론트\n","\n","밤이 되면 반짝이는 네오 도쿄. 고층 빌딩이 늘어서고, 네온...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb48aad40d0>, 'json_data': {'input': [\"file_path: data/akazukin1.txt  제1장: 데이터 프론트  밤이 되면 반짝이는 네오 도쿄. 고층 빌딩이 늘어서고, 네온사인이 거리를 수놓는다. 그 거리에서 빨간 두건을 쓴 소녀 미코는 불법 데이터 카우리아를 운반하는 배달원으로 일하고 있었다. 그녀는 어머니가 병에 걸려 치료비를 벌기 위해 데이터카우리아에 몸을 던지고 있었다.  그러던 어느 날, 미코는 중요한 데이터를 운반하는 임무를 맡게 된다. 그 데이터에는 거대 기업 '울프 코퍼레이션'의 시민에 대한 악랄한 지배를 폭로하는 정보가 담겨 있었다. 그녀는 데이터를 받아 목적지로 향한다.\"], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n","DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb47a4d7cd0>\n","DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb48aa5f6c0> server_hostname='api.openai.com' timeout=60.0\n","DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb48aaf30a0>\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:15:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'25'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999821'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'150a89f0aef74920c5d2b83b14fca02c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HskuOkig_Djbaf8VBtJJ80dq0G8HmH.iKvx5UQDmoDE-1700007337-0-AZYsPzQb+2TMME5mqHRUp1DC7uPzmFez7RH8PZXREygAgr01HJ0hVkbG80qIg1XahSpKV3pPQLux0hyFfnPfbMo=; path=/; expires=Wed, 15-Nov-23 00:45:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4OJ2yv1KhaS.Jyt2rFgzbTyyPnJjPsgjSMdd19jONZA-1700007337390-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82634d020f9c1d70-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제2장: 울프 코퍼레이션의 함정\n","\n","미코는 목적지인 술집 '할머니의 집'으로 향하는 길...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb48aaee680>, 'json_data': {'input': [\"file_path: data/akazukin2.txt  제2장: 울프 코퍼레이션의 함정  미코는 목적지인 술집 '할머니의 집'으로 향하는 길에 울프 코퍼레이션의 요원들에게 쫓기게 된다. 그들은 '빨간 망토'라는 데이터 카우리아에 대한 소문을 듣고 데이터를 탈취하려 했다. 미코는 교묘하게 요원들을 흩뿌리고 술집에 도착한다.\"], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:15:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'30'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999902'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'9b6ae1cdf13a5de5c8b37cc34b5d0eb9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82634d02f8ed1d70-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제3장: 배신과 재회\n","\n","술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb48aaee680>, 'json_data': {'input': [\"file_path: data/akazukin3.txt  제3장: 배신과 재회  술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기다리고 있었다. 료는 그녀의 어릴 적 친구이자 그 역시 울프 코퍼레이션과 싸우는 해커 집단의 일원이었다. 하지만 료는 미코에게 배신감을 느꼈고, 그녀가 데이터 카우리아에 몸을 던진 것에 화가 났다.  그럼에도 불구하고 미코는 료에게 데이터를 건네며 울프 코퍼레이션에 대한 반격을 믿기로 한다. 두 사람은 함께 울프 코퍼레이션의 음모를 밝혀내고 시민들을 구하기로 결심한다.\"], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:15:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'26'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999838'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'4ba0bacc2d118fc2fe84fcb2a66e5cb2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82634d040a981d70-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제4장: 울프 코퍼레이션의 붕괴\n","\n","미코와 료는 해커 집단과 함께 울프 코퍼레이션에 대...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb48aaee680>, 'json_data': {'input': ['file_path: data/akazukin4.txt  제4장: 울프 코퍼레이션의 붕괴  미코와 료는 해커 집단과 함께 울프 코퍼레이션에 대한 최후의 결전을 벌인다. 능숙한 해킹 기술과 신체 능력으로 그들은 울프 코퍼레이션의 보안을 차례로 뚫어 나간다. 그 과정에서 미코는 울프 코퍼레이션이 어머니의 병에 관여하고 있다는 사실을 알게 된다. 그녀는 분노에 휩싸여 울프코퍼레이션에 대한 복수를 다짐한다.'], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:15:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'31'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999873'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'd81887ed15922793c6531fe7a5bf49ef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82634d056cb11d70-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제5장: 결전의 순간\n","\n","미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb48aaee830>, 'json_data': {'input': ['file_path: data/akazukin5.txt  제5장: 결전의 순간  미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인 교활한 울프 박사와 대면한다. 울프 박사는 시민을 지배하려는 사악한 야망을 드러내며 자신의 압도적인 힘을 과시한다. 하지만 미코와 료는 서로를 도와가며 울프 박사와 싸우고 그의 약점을 찾아낸다.'], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:15:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'24'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999897'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'ea14dd193f7e708b4beebfb3bc76f5c0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82634d065e221d70-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제6장: 진실의 해방\n","\n","미코는 울프 박사의 약점을 파고들어 그를 쓰러뜨리는데 성공한다...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb48aaee830>, 'json_data': {'input': ['file_path: data/akazukin6.txt  제6장: 진실의 해방  미코는 울프 박사의 약점을 파고들어 그를 쓰러뜨리는데 성공한다. 그리고 해커 집단과 함께 울프 코퍼레이션의 악행을 세상에 공개하고 시민들을 해방시킨다. 이 승리로 미코의 어머니의 치료법도 찾아내고, 그녀의 병은 완치된다.'], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:15:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'23'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999909'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'd6befa8791512a8d2494323c236f78d3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82634d074f701d70-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n","DEBUG:llama_index.node_parser.node_utils:> Adding chunk: 제7장: 새로운 시작\n","\n","울프 코퍼레이션이 무너진 후, 미코와 료는 서로의 과거를 용서...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb48aaee680>, 'json_data': {'input': ['file_path: data/akazukin7.txt  제7장: 새로운 시작  울프 코퍼레이션이 무너진 후, 미코와 료는 서로의 과거를 용서하고 다시 우정을 회복한다. 미코는 데이터카우리아를 그만두고 료와 함께 새로운 길을 걷기 시작한다. 그들은 스스로의 힘으로 미래의 네오 도쿄를 더 나은 도시로 바꾸어 나갈 것을 다짐한다. 이것은 미코와 료, 그리고 전뇌 빨간 망토의 새로운 모험의 시작이었다.'], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:15:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'29'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999877'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'3ae53952352e9f8a8ce4eca0db51b00c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82634d0889441d70-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n"]}]},{"cell_type":"code","source":["# 사용할 llm 커스터마이징\n","from llama_index import GPTVectorStoreIndex, ServiceContext, LLMPredictor\n","from langchain.chat_models import ChatOpenAI\n","\n","# LLMPredicor 준비\n","llm_predictor = LLMPredictor(llm=ChatOpenAi(\n","    temperature=0, # 온도\n","    model_name=\"gpt-3.5-turbo\"  # 모델명\n","))\n","\n","# ServiceContext 준비\n","service_context = ServiceContext.from_defaults(\n","    llm_predictor=llm_predictor,\n",")\n","\n","# 인덱스 생성\n","index = GPTVectorStoreIndex.from_documents(\n","    documents,\n","    service_context=service_context,\n",")"],"metadata":{"id":"HRngU5MbVKRS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 청크 분할 규칙 커스터마이징\n","from llama_index import GPTVectorStoreIndex, PromptHelper, ServiceContext\n","\n","# PromptHelper 준비\n","prompt_helper=PromptHelper(\n","    mat_input_size=4096,# LLM 입력의 최대 토큰 수\n","    num_output=256, # LLM 출력의 토큰 수\n","    max_chunk_overlap=20, # 청크 오버랩의 최대 토큰 개수\n",")\n","\n","# ServiceContext 준비\n","service_context = ServiceContext.from_defaults(\n","    prompt_helper=prompt_helper\n",")\n","\n","# 인덱스 생성\n","index = GPTVectorStoreIndex.from_documents(\n","    documents,\n","    service_context=service_context,\n",")"],"metadata":{"id":"6AySBcY8YYUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 임베팅 모델 커스터 마이징\n","\n","# sentence_transformers 패키지 설치\n","!pip install sentence_transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYTClAIrZgDZ","executionInfo":{"status":"ok","timestamp":1700008655733,"user_tz":-540,"elapsed":22960,"user":{"displayName":"김재우","userId":"05418694853631208143"}},"outputId":"03b50400-92da-449d-a7cb-5fdf966a6bb9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentence_transformers\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81.9/86.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n","  Downloading transformers-4.35.1-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n","Collecting sentencepiece (from sentence_transformers)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n","  Downloading huggingface_hub-0.19.1-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n","Collecting huggingface-hub>=0.4.0 (from sentence_transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n","Building wheels for collected packages: sentence_transformers\n","  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=7bcb0e66a670e8e59b8070fc72086322b6d4f59f8743c747748f8adbf9588068\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built sentence_transformers\n","Installing collected packages: sentencepiece, safetensors, huggingface-hub, tokenizers, transformers, sentence_transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.14.1 transformers-4.35.1\n"]}]},{"cell_type":"code","source":["from langchain.embeddings import HuggingFaceEmbeddings\n","from llama_index import GPTVectorStoreIndex, ServiceContext, LangchainEmbedding\n","\n","# 임베딩 모델 준비\n","embed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n","    model_name=\"bongsoo/moco-sentencedistilbertV2.1\"\n","))\n","\n","# ServiceContext 준비\n","service_context = ServiceContext.from_defaults(\n","    embed_model=embed_model,\n",")\n","\n","# 인덱스 생성\n","index = GPTVectorStoreIndex.from_documents(\n","    documents,\n","    service_context=service_context,\n",")"],"metadata":{"id":"M8ywv9M2aR3X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 쿼리 엔진 생성"],"metadata":{"id":"Nq4ChMeZbrR5"}},{"cell_type":"code","source":["# 쿼리 엔진 생성\n","query_engine = index.as_query_engine()"],"metadata":{"id":"Xqhk0XkZb_Mm","executionInfo":{"status":"ok","timestamp":1700009144349,"user_tz":-540,"elapsed":402,"user":{"displayName":"김재우","userId":"05418694853631208143"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# 질의 응답"],"metadata":{"id":"2LEBqldYcQa8"}},{"cell_type":"code","source":["# 질의 응답\n","q = \"미코의 소꿉친구 이름은?\"\n","response = query_engine.query(q)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5SuiFaccO-4","executionInfo":{"status":"ok","timestamp":1700009381257,"user_tz":-540,"elapsed":125197,"user":{"displayName":"김재우","userId":"05418694853631208143"}},"outputId":"d4c0af15-2675-49cd-be73-bddbec998140"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7fb48a7f3400>, 'json_data': {'input': ['미코의 소꿉친구 이름은?'], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}\n","DEBUG:httpcore.connection:close.started\n","DEBUG:httpcore.connection:close.complete\n","DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n","DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb48aaf3190>\n","DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb48aa5f6c0> server_hostname='api.openai.com' timeout=60.0\n","DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb48aaf3070>\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:47:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'39'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999992'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'9a16fc810bb20454ac6d7c6e300b545f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TjlD3DLVI6gY7yLo5bjh68CLXilL76MDGNAdrmMhZTk-1700009256-0-AWR/LFINIwuf4MPyAsJyh0hhA530JpPI/+IwtdsSDre52HZ51ps9PSgJXBiwDmiFa9qBefpogZO+fofvU/JJ2A0=; path=/; expires=Wed, 15-Nov-23 01:17:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82637bd9ab15134d-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings \"200 OK\"\n","DEBUG:llama_index.indices.utils:> Top 2 nodes:\n","> [Node 1b75e906-5075-41e7-be37-40f45a5d05ac] [Similarity score:             0.822913] 제5장: 결전의 순간\n","\n","미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인 교활한 울프 박사와 대면한다. 울프 박사는 시민을 지배하려는 사악한 야망을 드러내며 자신...\n","> [Node e9783b7f-dfcd-4509-9ed0-c4c9c620a2c7] [Similarity score:             0.822396] 제3장: 배신과 재회\n","\n","술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기다리고 있었다. 료는 그녀의 어릴 적 친구이자 그 역시 울프 코퍼레이션과 싸우는 해커 집단...\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.SYSTEM: 'system'>, 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': <MessageRole.USER: 'user'>, 'content': \"Context information is below.\\n---------------------\\nfile_path: data/akazukin5.txt\\n\\n제5장: 결전의 순간\\n\\n미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인 교활한 울프 박사와 대면한다. 울프 박사는 시민을 지배하려는 사악한 야망을 드러내며 자신의 압도적인 힘을 과시한다. 하지만 미코와 료는 서로를 도와가며 울프 박사와 싸우고 그의 약점을 찾아낸다.\\n\\nfile_path: data/akazukin3.txt\\n\\n제3장: 배신과 재회\\n\\n술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기다리고 있었다. 료는 그녀의 어릴 적 친구이자 그 역시 울프 코퍼레이션과 싸우는 해커 집단의 일원이었다. 하지만 료는 미코에게 배신감을 느꼈고, 그녀가 데이터 카우리아에 몸을 던진 것에 화가 났다.\\n\\n그럼에도 불구하고 미코는 료에게 데이터를 건네며 울프 코퍼레이션에 대한 반격을 믿기로 한다. 두 사람은 함께 울프 코퍼레이션의 음모를 밝혀내고 시민들을 구하기로 결심한다.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: 미코의 소꿉친구 이름은?\\nAnswer: \"}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n","DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n","DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb47a199b10>\n","DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb48aa5f9c0> server_hostname='api.openai.com' timeout=60.0\n","DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb47a198d30>\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.failed exception=ReadTimeout(TimeoutError('The read operation timed out'))\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","INFO:openai._base_client:Retrying request to /chat/completions in 0.915169 seconds\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.SYSTEM: 'system'>, 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': <MessageRole.USER: 'user'>, 'content': \"Context information is below.\\n---------------------\\nfile_path: data/akazukin5.txt\\n\\n제5장: 결전의 순간\\n\\n미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인 교활한 울프 박사와 대면한다. 울프 박사는 시민을 지배하려는 사악한 야망을 드러내며 자신의 압도적인 힘을 과시한다. 하지만 미코와 료는 서로를 도와가며 울프 박사와 싸우고 그의 약점을 찾아낸다.\\n\\nfile_path: data/akazukin3.txt\\n\\n제3장: 배신과 재회\\n\\n술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기다리고 있었다. 료는 그녀의 어릴 적 친구이자 그 역시 울프 코퍼레이션과 싸우는 해커 집단의 일원이었다. 하지만 료는 미코에게 배신감을 느꼈고, 그녀가 데이터 카우리아에 몸을 던진 것에 화가 났다.\\n\\n그럼에도 불구하고 미코는 료에게 데이터를 건네며 울프 코퍼레이션에 대한 반격을 믿기로 한다. 두 사람은 함께 울프 코퍼레이션의 음모를 밝혀내고 시민들을 구하기로 결심한다.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: 미코의 소꿉친구 이름은?\\nAnswer: \"}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n","DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n","DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb48aa57340>\n","DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb48aa5f9c0> server_hostname='api.openai.com' timeout=60.0\n","DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb48aa574f0>\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.failed exception=ReadTimeout(TimeoutError('The read operation timed out'))\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","INFO:openai._base_client:Retrying request to /chat/completions in 1.901448 seconds\n","DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.SYSTEM: 'system'>, 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': <MessageRole.USER: 'user'>, 'content': \"Context information is below.\\n---------------------\\nfile_path: data/akazukin5.txt\\n\\n제5장: 결전의 순간\\n\\n미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인 교활한 울프 박사와 대면한다. 울프 박사는 시민을 지배하려는 사악한 야망을 드러내며 자신의 압도적인 힘을 과시한다. 하지만 미코와 료는 서로를 도와가며 울프 박사와 싸우고 그의 약점을 찾아낸다.\\n\\nfile_path: data/akazukin3.txt\\n\\n제3장: 배신과 재회\\n\\n술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기다리고 있었다. 료는 그녀의 어릴 적 친구이자 그 역시 울프 코퍼레이션과 싸우는 해커 집단의 일원이었다. 하지만 료는 미코에게 배신감을 느꼈고, 그녀가 데이터 카우리아에 몸을 던진 것에 화가 났다.\\n\\n그럼에도 불구하고 미코는 료에게 데이터를 건네며 울프 코퍼레이션에 대한 반격을 믿기로 한다. 두 사람은 함께 울프 코퍼레이션의 음모를 밝혀내고 시민들을 구하기로 결심한다.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: 미코의 소꿉친구 이름은?\\nAnswer: \"}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n","DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n","DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb48a7df5e0>\n","DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb48aa5f9c0> server_hostname='api.openai.com' timeout=60.0\n","DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb47a204be0>\n","DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_headers.complete\n","DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:send_request_body.complete\n","DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Nov 2023 00:49:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vgoz0mva2kq7zygx3mmtwr9q'), (b'openai-processing-ms', b'605'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3500'), (b'x-ratelimit-limit-tokens', b'90000'), (b'x-ratelimit-remaining-requests', b'3499'), (b'x-ratelimit-remaining-tokens', b'89578'), (b'x-ratelimit-reset-requests', b'17ms'), (b'x-ratelimit-reset-tokens', b'280ms'), (b'x-request-id', b'73c5b998c294a8c3ceb5309ed254097f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1IQr6eC069PSHEX4vrADWsK7WPGNdWLqKj7F7VSZVvc-1700009380-0-ATMog5aOLl8PvVWEAvGlzMcn0cFg+XMMIwjKUYl6e3jCwlb20XN3+tlYSnvzILtXWG0bOPo/2XixVZ1hw/kmXvI=; path=/; expires=Wed, 15-Nov-23 01:19:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=_7IGmFGhP0RzC92smYmU7ecNtGoLF0.EzqNZy6R25SY-1700009380126-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'82637edcbbc54560-ATL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n","DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n","DEBUG:httpcore.http11:receive_response_body.complete\n","DEBUG:httpcore.http11:response_closed.started\n","DEBUG:httpcore.http11:response_closed.complete\n","DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n","DEBUG:llama_index.llm_predictor.base:료\n","료\n"]}]},{"cell_type":"code","source":["# 응답\n","print(\"response : \", response.response, \"\\n\")\n","\n","# 소스\n","print(\"source_nodes : \", response.source_nodes, \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKs62xlacqJ_","executionInfo":{"status":"ok","timestamp":1700009387579,"user_tz":-540,"elapsed":412,"user":{"displayName":"김재우","userId":"05418694853631208143"}},"outputId":"7cea8554-6809-4709-f5dc-1b97c1e53656"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["response :  료 \n","\n","source_nodes :  [NodeWithScore(node=TextNode(id_='1b75e906-5075-41e7-be37-40f45a5d05ac', embedding=None, metadata={'file_path': 'data/akazukin5.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ed7d46c6-003a-4ee0-80fa-a048399bbb30', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/akazukin5.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, hash='aaa833804c60686d89a7f25f5e4348481490c3542510cdf15e64392a8b89f734')}, hash='43df6563e1bde085bf1ab7d3228f305b78729fb7cb3365468aaec427f5b99f13', text='제5장: 결전의 순간\\n\\n미코와 료는 마침내 울프 코퍼레이션의 최상층에 도착해 CEO인 교활한 울프 박사와 대면한다. 울프 박사는 시민을 지배하려는 사악한 야망을 드러내며 자신의 압도적인 힘을 과시한다. 하지만 미코와 료는 서로를 도와가며 울프 박사와 싸우고 그의 약점을 찾아낸다.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8229125522361105), NodeWithScore(node=TextNode(id_='e9783b7f-dfcd-4509-9ed0-c4c9c620a2c7', embedding=None, metadata={'file_path': 'data/akazukin3.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, excluded_embed_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e8e205ea-b0c2-4dbb-8766-6fca40240bf1', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/akazukin3.txt', 'creation_date': '2023-11-15', 'last_modified_date': '2023-11-15', 'last_accessed_date': '2023-11-15'}, hash='46ab05d7966d65d132d327118a460e5279798448f9b18456dc2c7a9573e528d3')}, hash='92dfd000d0329dab21cbfc164b35181376338b2326b247efb67be85aa20d4dcb', text=\"제3장: 배신과 재회\\n\\n술집 '할머니의 집'에서 미코는 데이터를 받을 사람인 료를 기다리고 있었다. 료는 그녀의 어릴 적 친구이자 그 역시 울프 코퍼레이션과 싸우는 해커 집단의 일원이었다. 하지만 료는 미코에게 배신감을 느꼈고, 그녀가 데이터 카우리아에 몸을 던진 것에 화가 났다.\\n\\n그럼에도 불구하고 미코는 료에게 데이터를 건네며 울프 코퍼레이션에 대한 반격을 믿기로 한다. 두 사람은 함께 울프 코퍼레이션의 음모를 밝혀내고 시민들을 구하기로 결심한다.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8223964687099058)] \n","\n"]}]}]}